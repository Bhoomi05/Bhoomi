{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from random import randrange,uniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import PCA\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/hp/Desktop/DATA SCIENTISTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "santander_train = pd.read_csv(\"train.csv\")\n",
    "santander_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier analysis\n",
    "import seaborn as sns\n",
    "x_train=santander_train.iloc[:,2:]\n",
    "y_train=santander_train['target']\n",
    "sns.boxplot(x=santander_train['var_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save numeric names\n",
    "cnames= santander_train.iloc[:, 1:201]\n",
    "#Detect and delete outliers from data\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    q75, q25 = np.percentile(santander_train.loc[:,i], [75 ,25])\n",
    "    iqr = q75 - q25\n",
    "    min = q25 - (iqr*1.5)\n",
    "    max = q75 + (iqr*1.5)\n",
    "    print(min)\n",
    "    print(max)\n",
    "    santander_train = santander_train.drop(santander_train[santander_train.loc[:,i] < min].index)\n",
    "    santander_train = santander_train.drop(santander_train[santander_train.loc[:,i] > max].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect and replace with NA\n",
    "#Extract quartiles\n",
    "q75, q25 = np.percentile(santander_train['var_44'], [75 ,25])\n",
    "#Calculate IQR\n",
    "iqr = q75 - q25\n",
    "#Calculate inner and outer fence\n",
    "minimum = q25 - (iqr*1.5)\n",
    "maximum = q75 + (iqr*1.5)\n",
    "#Replace with NA\n",
    "santander_train.loc[santander_train['var_44'] < minimum,:'var_44'] = np.nan\n",
    "santander_train.loc[santander_train['var_44'] > maximum,:'var_44'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing value Analysis\n",
    "#Create dataframe with missing percentage\n",
    "missing_val = pd.DataFrame(santander_train.isnull().sum())\n",
    "#Reset index\n",
    "missing_val = missing_val.reset_index()\n",
    "#Rename variable\n",
    "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_percentage'})\n",
    "#Calculate percentage\n",
    "missing_val['Missing_percentage'] = (missing_val['Missing_percentage']/len(santander_train))*100\n",
    "#descending order\n",
    "missing_val = missing_val.sort_values('Missing_percentage', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation method\n",
    "#actual = 11.7058\n",
    "#Mean = 10.628882\n",
    "#Median =  10.4940\n",
    "#KNN = 10.5792\n",
    "#create missing value\n",
    "santander_train['var_0'].loc[4] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate using mean\n",
    "santander_train['var_0'] = santander_train['var_0'].fillna(santander_train['var_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate using median\n",
    "santander_train['var_0'] = santander_train['var_0'].fillna(santander_train['var_0'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN imputation\n",
    "#Assigning levels to the categories\n",
    "lis = []\n",
    "for i in range(0, santander_train.shape[1]):\n",
    "    print(i)\n",
    "    if(santander_train.iloc[:,i].dtypes == 'object'):\n",
    "        santander_train.iloc[:,i] = pd.Categorical(santander_train.iloc[:,i])\n",
    "        santander_train.iloc[:,i] = santander_train.iloc[:,i].cat.codes \n",
    "        santander_train.iloc[:,i] = santander_train.iloc[:,i].astype('object')\n",
    "        lis.append(santander_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply KNN imputation algorithm\\n\",\n",
    "santander_train = pd.DataFrame(kNN(k = 3).fit_transform(santander_train), columns = santander_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze imputation using median\n",
    "santander_train = santander_train.fillna(santander_train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into proper datatypes\n",
    "for i in lis:\n",
    "    santander_train.loc[:,i] = santander_train.loc[:,i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(santander_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection\n",
    "##Correlation analysis\n",
    "#Correlation plot\n",
    "cnames= santander_train.iloc[:, 3:201]\n",
    "df_corr= santander_train.iloc[:,3:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the width and hieght of the plot\n",
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "#Generate correlation matrix\n",
    "corr = df_corr.corr()\n",
    "#Plot using seaborn library\n",
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_train = santander_train.drop(['var_25', 'var_36', 'var_55', 'var_79', 'var_106', 'var_119', 'var_162', 'var_183'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "df = santander_train.copy()\n",
    "santander_train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality check\\n\",\n",
    "%matplotlib inline \n",
    "plt.hist(santander_train['var_100'], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation\n",
    "cnames= santander_train.iloc[:, 3:201]\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    santander_train[i] = (santander_train[i] - min(santander_train[i]))/(max(santander_train[i]) - min(santander_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into train and test\\n\",\n",
    "X = santander_train.values[:, 2:193]\n",
    "Y = santander_train.values[:,1]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us prepare data for logistic regression\\n\",\n",
    "#replace target categories with Yes or No\\n\",\n",
    "santander_train['target'] = santander_train['target'].replace('No', 0)\n",
    "santander_train['target'] = santander_train['target'].replace('Yes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create logistic data. Save target variable first\n",
    "santander_train_logit = pd.DataFrame(santander_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_train_logit = santander_train_logit.join(santander_train['cnames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santander_train_logit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Index = np.random.rand(len(santander_train_logit)) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = santander_train_logit[Sample_Index]\n",
    "test = santander_train_logit[~Sample_Index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select column indexes for independent variables\n",
    "train_cols = train.columns[3:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built Logistic Regression\n",
    "import statsmodels.api as sm\n",
    "logit = sm.Logit(train['target'], train[train_cols]).fit()\n",
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "test['Actual_prob'] = logit.predict(test[train_cols])\n",
    "test['ActualVal'] = 1\n",
    "test.loc[test.Actual_prob < 0.5, 'ActualVal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(test['target'], test['ActualVal'])\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "#check accuracy of model\n",
    "accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "(FN*100)/(FN+TP)\n",
    "#Accuracy: 83.33\n",
    "#FNR: 52.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 9).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test cases\n",
    "KNN_Predictions = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "CM = pd.crosstab(y_test, KNN_Predictions)\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "#check accuracy of model\n",
    "accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "#False Negative rate\n",
    "(FN*100)/(FN+TP)\n",
    "#Accuracy: 92.23\n",
    "#FNR: 81.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes implementation\\n\",\n",
    "NB_model = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test cases\n",
    "NB_Predictions = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(y_test, NB_Predictions)\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "#check accuracy of model\n",
    "accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "#False Negative rate\n",
    "(FN*100)/(FN+TP)\n",
    "#Accuracy: 86.92\n",
    "#FNR: 53.44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
